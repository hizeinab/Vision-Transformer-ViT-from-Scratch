# Vision-Transformer-ViT-from-Scratch
This notebook implements a Vision Transformer (ViT) model from scratch using PyTorch. The ViT architecture is introduced in the machine learning research paper titled "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale". The goal is to understand the core components of a ViT and train it on a small dataset.
